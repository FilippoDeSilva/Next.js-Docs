name: Mirror & Archive Next.js Docs (with Git LFS)

on:
  workflow_dispatch:
  schedule:
    - cron: "0 3 * * *" # daily at 3 AM UTC

jobs:
  download-docs:
    runs-on: ubuntu-latest
    env:
      BASE_URL: "https://nextjs.org"
      DOCS_PATH: "/docs"
      MIRROR_DIR: "nextjs-docs"
      PDF_DIR: "pdf_output"
      FINAL_DIR: "docs"
      FINAL_PDF: "NextJS_Docs_Complete.pdf"
      HTRACK_SOCKETS: 12

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Install system packages and Python deps (including Playwright)
        run: |
          sudo apt-get update
          sudo apt-get install -y httrack wkhtmltopdf pdftk git-lfs ghostscript xvfb
          python -m pip install --upgrade pip
          pip install playwright beautifulsoup4 requests PyPDF2 reportlab
          # install Playwright browsers and system deps
          python -m playwright install --with-deps

      - name: Initialize Git LFS
        run: |
          git lfs install
          git lfs track "*.pdf"
          git add .gitattributes || true
          git commit -m "ðŸ§© Track PDFs with Git LFS" || echo "No new LFS tracking changes"

      - name: Mirror Next.js Docs only (httrack)
        run: |
          rm -rf "${MIRROR_DIR}"
          mkdir -p "${MIRROR_DIR}"
          httrack "${BASE_URL}${DOCS_PATH}" \
            --path "${MIRROR_DIR}" \
            "+${BASE_URL}${DOCS_PATH}*" "-*" \
            --stay-on-same-domain \
            --mirror \
            --robots=0 \
            --disable-security-limits \
            --keep-alive \
            --sockets=${HTRACK_SOCKETS} \
            --depth=0 \
            --quiet || true

      - name: Extract sidebar order (Playwright + BeautifulSoup)
        run: |
          python - <<'PY'
          import os, json
          from playwright.sync_api import sync_playwright
          from bs4 import BeautifulSoup

          BASE = os.environ["BASE_URL"] + os.environ["DOCS_PATH"]
          with sync_playwright() as p:
              browser = p.chromium.launch()
              page = browser.new_page()
              page.goto(BASE, wait_until="networkidle", timeout=180000)
              html = page.content()
              browser.close()
          soup = BeautifulSoup(html, "html.parser")

          ordered = []
          # Find sidebar containers first, then walk their lists preserving order
          # This is resilient: collects links from visible nav UL/LI blocks in document order.
          for nav in soup.find_all(["nav", "aside"]):
              for ul in nav.find_all("ul", recursive=True):
                  for li in ul.find_all("li", recursive=False):
                      a = li.find("a", href=True)
                      if a:
                          href = a["href"]
                          if isinstance(href, str) and href.startswith("/docs") and "#" not in href:
                              full = os.environ["BASE_URL"] + href
                              if full not in ordered:
                                  ordered.append(full)
                      # also include nested anchor tags inside this li
                      for na in li.find_all("a", href=True):
                          nh = na["href"]
                          if isinstance(nh, str) and nh.startswith("/docs") and "#" not in nh:
                              full = os.environ["BASE_URL"] + nh
                              if full not in ordered:
                                  ordered.append(full)

          # Fallback: if no links found, include top-level /docs
          if not ordered:
              ordered = [os.environ["BASE_URL"] + os.environ["DOCS_PATH"]]

          with open("sidebar_order.json", "w") as f:
              json.dump(ordered, f, indent=2)
          print(f"Extracted {len(ordered)} links")
          PY

      - name: Build mapping from sidebar URL -> local mirrored file (if present)
        run: |
          python - <<'PY'
          import json, os, glob
          MIRROR = os.environ["MIRROR_DIR"]
          # Try to locate httrack root directory (e.g., nextjs-docs/www.nextjs.org)
          candidate_roots = []
          for root in glob.glob(os.path.join(MIRROR, "**", "www.*"), recursive=True):
              candidate_roots.append(root)
          # prefer explicit root if present, else MIRROR
          root = candidate_roots[0] if candidate_roots else MIRROR

          with open("sidebar_order.json") as f:
              links = json.load(f)
          mapped = []
          for url in links:
              path = url.replace("https://", "").replace("http://", "")
              # candidate local paths produced by httrack
              candidates = [
                  os.path.join(root, path + ".html"),
                  os.path.join(root, path, "index.html"),
                  os.path.join(MIRROR, path + ".html"),
                  os.path.join(MIRROR, path, "index.html"),
              ]
              found = next((c for c in candidates if os.path.exists(c)), None)
              mapped.append({"url": url, "file": found})
          with open("ordered_mapping.json", "w") as f:
              json.dump(mapped, f, indent=2)
          print("Wrote ordered_mapping.json with", len(mapped), "entries")
          PY

      - name: Prepare hide CSS (remove header, sidebar, footer, feedback)
        run: |
          cat > hide_sections.css <<'CSS'
          /* user-specified selectors (escaped/resilient) */
          [class*="header-module__Pc0Sva__header"],
          [class*="header-module__Pc0Sva__sticky"],
          [class*="footer-module__rV1DKq__footer"],
          [class*="feedback-module__j8fpJW__inlineWrapper"],
          [class*="feedback-module__j8fpJW__inlineWrapperClosed"],
          div[class*="sticky"][class*="top-"][class*="md:flex"][class*="md:shrink-0"][class*="md:flex-col"][class*="md:justify-between"] {
            display: none !important;
            visibility: hidden !important;
            height: 0 !important;
            overflow: hidden !important;
          }
          footer, .footer, [id*="footer"], [class*="Footer"] {
            display: none !important;
          }
          CSS

      - name: Render pages to PDF in sidebar order (sequential, local preferred, live fallback)
        run: |
          mkdir -p "${PDF_DIR}"
          python - <<'PY'
          import json, os, subprocess, time
          with open("ordered_mapping.json") as f:
              mapped = json.load(f)
          PDF_DIR = os.environ["PDF_DIR"]
          hide_css = os.path.abspath("hide_sections.css")
          failed = []
          for item in mapped:
              url = item["url"]
              local = item["file"]
              safe = url.replace("https://", "").replace("http://", "").replace("/", "-").strip("-")
              out = os.path.join(PDF_DIR, f"{safe}.pdf")
              print("Rendering:", url, "->", out)
              if local:
                  src = os.path.abspath(local)
                  cmd = [
                    "xvfb-run", "wkhtmltopdf",
                    "--enable-local-file-access",
                    "--load-error-handling", "ignore",
                    "--user-style-sheet", hide_css,
                    "--quiet",
                    src, out
                  ]
              else:
                  cmd = [
                    "xvfb-run", "wkhtmltopdf",
                    "--load-error-handling", "ignore",
                    "--user-style-sheet", hide_css,
                    "--quiet",
                    url, out
                  ]
              try:
                  subprocess.run(cmd, check=True, timeout=240)
                  time.sleep(0.25)
              except Exception as e:
                  print("Failed to render:", url, e)
                  failed.append({"url": url, "error": str(e)})
          if failed:
              print("Some pages failed to render:", len(failed))
              with open("render_errors.json","w") as ef:
                  import json
                  json.dump(failed, ef, indent=2)
          PY

      - name: Merge PDFs sequentially and add cover + bookmarks
        run: |
          python - <<'PY'
          import os, json
          from PyPDF2 import PdfMerger
          from reportlab.lib.pagesizes import A4
          from reportlab.pdfgen import canvas

          PDF_DIR = os.environ["PDF_DIR"]
          FINAL_DIR = os.environ["FINAL_DIR"]
          FINAL_PDF = os.environ["FINAL_PDF"]
          BASE = os.environ["BASE_URL"] + os.environ["DOCS_PATH"]
          os.makedirs(PDF_DIR, exist_ok=True)
          os.makedirs(FINAL_DIR, exist_ok=True)

          def create_cover(path):
              c = canvas.Canvas(path, pagesize=A4)
              c.setFont("Helvetica-Bold", 28)
              c.drawCentredString(300, 750, "Next.js Documentation")
              c.setFont("Helvetica", 14)
              c.drawCentredString(300, 720, "Generated via GitHub Actions")
              c.showPage()
              c.save()

          merger = PdfMerger()
          cover = os.path.join(PDF_DIR, "cover.pdf")
          create_cover(cover)
          merger.append(cover, import_outline=False)

          with open("ordered_mapping.json") as f:
              mapped = json.load(f)

          page_index = len(merger.pages)
          for item in mapped:
              url = item["url"]
              safe = url.replace("https://", "").replace("http://", "").replace("/", "-").strip("-")
              pdf_path = os.path.join(PDF_DIR, f"{safe}.pdf")
              if not os.path.exists(pdf_path):
                  # skip missing pages
                  continue
              merger.append(pdf_path, import_outline=False)
              # make a human-friendly title
              title = url.replace(BASE + "/", "").replace("-", " ").title() if url.startswith(BASE + "/") else url
              try:
                  merger.add_outline_item(title, page_index)
              except Exception:
                  pass
              page_index = len(merger.pages)

          out_path = os.path.join(FINAL_DIR, FINAL_PDF)
          merger.write(out_path)
          merger.close()
          print("Merged to", out_path)
          PY

      - name: Compress final PDF (Ghostscript)
        run: |
          gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/ebook \
             -dNOPAUSE -dQUIET -dBATCH \
             -sOutputFile="${FINAL_DIR}/${FINAL_PDF}.tmp" \
             "${FINAL_DIR}/${FINAL_PDF}" || true
          if [ -f "${FINAL_DIR}/${FINAL_PDF}.tmp" ]; then
            mv "${FINAL_DIR}/${FINAL_PDF}.tmp" "${FINAL_DIR}/${FINAL_PDF}"
          fi
          echo "Compressed final PDF if possible"

      - name: Commit & Push (with LFS) safely
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"
          git fetch origin main --quiet || true
          git checkout main || git checkout -b main
          git pull --rebase origin main || true
          git add "${FINAL_DIR}/${FINAL_PDF}" || true
          git commit -m "ðŸ“š Update Next.js Docs (Git LFS upload)" || echo "No PDF changes"
          git push origin main --recurse-submodules=on-demand || echo "Push failed; check permissions and LFS"

      - name: Upload Final PDF as Artifact
        uses: actions/upload-artifact@v4
        with:
          name: NextJS_Docs_Complete
          path: docs/NextJS_Docs_Complete.pdf