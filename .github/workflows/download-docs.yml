name: Build Next.js Docs PDF & HTML

on:
  push:
    paths:
      - 'nextjs-docs/canary_docs/**'
  workflow_dispatch:

jobs:
  build-docs:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: 20

    - name: Install dependencies
      run: sudo apt-get install -y jq

    - name: Build PDF & HTML from MDX/MD
      run: |
        set -euo pipefail

        echo "Docs changed. Building PDF and HTML..."

        mkdir -p pdf-docs html_cache tmp_mdx_project

        DOCS_PATH="nextjs-docs/canary_docs"
        FILES_JSON="tmp_files.json"
        HTML_FILE="pdf-docs/NextJS_Canary_Docs.html"
        PDF_FILE="pdf-docs/NextJS_Canary_Docs.pdf"

        # Ensure docs folder exists
        if [ ! -d "$DOCS_PATH" ]; then
          echo "ERROR: Docs folder not found: $DOCS_PATH"
          exit 1
        fi

        # Collect all MD/MDX files
        mapfile -t files < <(find "$DOCS_PATH" -type f \( -name "*.md" -o -name "*.mdx" \) | sort)
        if [ "${#files[@]}" -eq 0 ]; then
          echo "No Markdown/MDX files found in $DOCS_PATH"
          exit 1
        fi

        # Save file list as JSON
        printf '%s\n' "${files[@]}" | jq -R -s -c 'split("\n")[:-1]' > "$FILES_JSON"
        echo "Saved ${#files[@]} files to $FILES_JSON"

        # Init temporary Node project
        cd tmp_mdx_project
        npm init -y
        npm install @mdx-js/mdx puppeteer
        cd ../

        # HTML header
        echo "<html><head><meta charset='UTF-8'></head><body>" > "$HTML_FILE"

        # Multi-threaded MDX compilation
        node -e "
        const fs = require('fs');
        const path = require('path');
        const { Worker } = require('worker_threads');
        const files = JSON.parse(fs.readFileSync('$FILES_JSON','utf8'));
        const htmlDir = path.resolve('html_cache');
        if(!fs.existsSync(htmlDir)) fs.mkdirSync(htmlDir);

        const maxWorkers = Math.min(require('os').cpus().length, 4);
        let index = 0;

        function runWorker(file) {
          return new Promise((resolve,reject) => {
            const worker = new Worker(\`
              const { parentPort, workerData } = require('worker_threads');
              const fs = require('fs');
              const path = require('path');
              const mdx = require(workerData.mdx);

              (async () => {
                try {
                  const content = fs.readFileSync(workerData.file,'utf8');
                  const html = '<div>'+ (await mdx.compile(content)).value + '</div>';
                  const outFile = path.join(workerData.htmlDir, path.basename(workerData.file).replace(/[\\/:\\s]/g,'_')+'.html');
                  fs.writeFileSync(outFile, html);
                  parentPort.postMessage(workerData.file);
                } catch(e) { parentPort.postMessage({error:e.message}); }
              })();
            \`, { eval:true, workerData: { file, htmlDir, mdx: path.resolve('tmp_mdx_project/node_modules/@mdx-js/mdx') } });
            worker.on('message', resolve);
            worker.on('error', reject);
            worker.on('exit', code => { if(code!==0) reject(new Error('Worker exit '+code)); });
          });
        }

        async function runQueue() {
          const active = [];
          while(index < files.length || active.length > 0){
            while(index < files.length && active.length < maxWorkers){
              active.push(runWorker(files[index++]));
            }
            await Promise.race(active).then(() => {
              active.splice(active.findIndex(p => p.isFulfilled || p.isResolved),1);
            }).catch(() => { active.splice(active.findIndex(p => p.isRejected),1); });
          }
        }

        runQueue()
          .then(() => {
            const htmlFiles = fs.readdirSync(htmlDir).sort();
            for(const f of htmlFiles){
              fs.appendFileSync('$HTML_FILE', fs.readFileSync(path.join(htmlDir,f),'utf8') + '\\n');
            }
            process.exit(0);
          })
          .catch(err => { console.error(err); process.exit(1); });
        "

        # Close HTML
        echo "</body></html>" >> "$HTML_FILE"

        # Convert HTML â†’ PDF
        node -e "
        const puppeteer = require('./tmp_mdx_project/node_modules/puppeteer');
        (async () => {
          const browser = await puppeteer.launch({args:['--no-sandbox','--disable-setuid-sandbox'],timeout:0});
          const page = await browser.newPage();
          await page.goto('file://' + process.cwd() + '/$HTML_FILE', {waitUntil: 'networkidle0'});
          await page.pdf({path: '$PDF_FILE', format: 'A4', printBackground: true});
          await browser.close();
        })();
        "

        # Record docs hash
        echo "f8816b06" > docs_hash.txt
        echo "Recorded new docs hash."

    - name: Upload artifacts (PDF + HTML)
      uses: actions/upload-artifact@v4
      with:
        name: nextjs-canary-docs
        path: |
          pdf-docs/NextJS_Canary_Docs.pdf
          pdf-docs/NextJS_Canary_Docs.html

    - name: Commit PDF/HTML to branch
      run: |
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        git checkout -B docs-output
        git add pdf-docs/NextJS_Canary_Docs.pdf pdf-docs/NextJS_Canary_Docs.html docs_hash.txt
        git commit -m "Update compiled Next.js Canary docs"
        git push -u origin docs-output --force
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}