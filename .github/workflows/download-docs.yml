name: Next.js Docs Full PDF

on:
  workflow_dispatch:
  schedule:
    - cron: "0 0 * * *" # every midnight

jobs:
  build-docs:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libpango-1.0-0 libcairo2 libjpeg-dev libgif-dev
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 weasyprint tqdm

      - name: Scrape Docs & Build PDF
        run: |
          mkdir -p output pages assets
          python - <<'EOF'
          import os, re, requests, threading, queue
          from bs4 import BeautifulSoup
          from weasyprint import HTML, CSS
          from tqdm import tqdm

          BASE_URL = "https://nextjs.org/docs"
          OUTPUT_FILE = "output/nextjs-docs-dark.pdf"
          visited, q = set(), queue.Queue()
          lock = threading.Lock()

          def fetch(url):
              try:
                  r = requests.get(url, timeout=10)
                  r.raise_for_status()
                  return r.text
              except Exception as e:
                  print(f"❌ Failed {url}: {e}")
                  return None

          def save_html(path, html):
              with open(path, "w", encoding="utf-8") as f:
                  f.write(html)

          def worker():
              while True:
                  try:
                      url = q.get(timeout=2)
                  except:
                      return
                  if url in visited: 
                      q.task_done(); continue
                  with lock: visited.add(url)
                  html = fetch(url)
                  if not html: 
                      q.task_done(); continue

                  soup = BeautifulSoup(html, "html.parser")

                  # Inject dark mode CSS
                  dark_css = """
                  html, body { background: #0d1117 !important; color: #c9d1d9 !important; }
                  h1,h2,h3,h4,h5,h6 { color: #58a6ff !important; }
                  a { color: #58a6ff !important; }
                  code, pre { background: #161b22 !important; color: #f0f6fc !important; }
                  """
                  style_tag = soup.new_tag("style")
                  style_tag.string = dark_css
                  soup.head.append(style_tag)

                  # Save HTML locally
                  fname = "pages/" + re.sub(r"[^a-zA-Z0-9]", "_", url) + ".html"
                  save_html(fname, str(soup))

                  # Queue internal links
                  for a in soup.find_all("a", href=True):
                      href = a["href"]
                      if href.startswith("/docs"):
                          q.put("https://nextjs.org" + href)

                  q.task_done()

          # Seed queue
          q.put(BASE_URL)

          # Launch threads
          threads = []
          for _ in range(8):  # multithreaded
              t = threading.Thread(target=worker, daemon=True)
              t.start()
              threads.append(t)

          q.join()

          print(f"✅ Scraped {len(visited)} pages")

          # Merge into one PDF
          all_html = []
          for f in sorted(os.listdir("pages")):
              if f.endswith(".html"):
                  all_html.append("pages/" + f)

          HTML(string="".join(open(f, encoding="utf-8").read() for f in all_html)).write_pdf(
              OUTPUT_FILE,
              stylesheets=[CSS(string="body { font-family: system-ui; }")]
          )
          print(f"📄 PDF saved: {OUTPUT_FILE}")
          EOF

      - name: Upload Docs PDF
        uses: actions/upload-artifact@v4
        with:
          name: nextjs-docs-dark
          path: output/nextjs-docs-dark.pdf