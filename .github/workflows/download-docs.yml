name: ğŸ§­ Next.js Docs to PDF

on:
  workflow_dispatch:
  schedule:
    - cron: "0 6 * * *" # daily

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: ğŸ§¹ Checkout repo
        uses: actions/checkout@v4

      - name: âš™ï¸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: ğŸ“¦ Install dependencies
        run: |
          pip install aiohttp beautifulsoup4 fpdf2

      - name: ğŸ§  Run Scraper
        run: |
          python - <<'EOF'
          import asyncio, aiohttp, re
          from bs4 import BeautifulSoup
          from fpdf import FPDF

          BASE_URL = "https://nextjs.org/docs"
          HEADERS = {"User-Agent": "Mozilla/5.0"}

          async def get_latest_version(session):
              async with session.get(BASE_URL) as resp:
                  html = await resp.text()
                  match = re.search(r'/docs/(\d+\.\d+\.\d+)/', html)
                  if match:
                      ver = match.group(1)
                      print(f"ğŸ§­ Latest version detected: {ver}")
                      return f"https://nextjs.org/docs/{ver}/"
                  print("âš ï¸ No version found, using default /docs/app/")
                  return "https://nextjs.org/docs/app/"

          async def get_links(session, docs_url):
              async with session.get(docs_url) as resp:
                  html = await resp.text()
                  soup = BeautifulSoup(html, "html.parser")
                  sidebar_links = []
                  for a in soup.find_all("a", href=True):
                      href = a["href"]
                      if "/docs/" in href and not any(x in href for x in ["#", "feedback"]):
                          if not href.startswith("http"):
                              href = f"https://nextjs.org{href}"
                          sidebar_links.append(href)
                  sidebar_links = list(dict.fromkeys(sidebar_links))
                  print(f"ğŸ”— Found {len(sidebar_links)} sidebar links")
                  return sidebar_links

          async def fetch_page(session, url):
              try:
                  async with session.get(url, headers=HEADERS) as resp:
                      html = await resp.text()
                      soup = BeautifulSoup(html, "html.parser")
                      # Remove feedback sections
                      for fb in soup.select(".feedback-module__j8fpJW__inlineWrapper"):
                          fb.decompose()
                      title = soup.title.string.strip() if soup.title else url
                      main = soup.find("main") or soup
                      text = main.get_text(separator="\n", strip=True)
                      return (title, text)
              except Exception as e:
                  print(f"âŒ Error fetching {url}: {e}")
                  return None

          async def scrape_docs():
              async with aiohttp.ClientSession() as session:
                  docs_url = await get_latest_version(session)
                  links = await get_links(session, docs_url)
                  results = []
                  for i, link in enumerate(links):
                      print(f"ğŸ“„ ({i+1}/{len(links)}) {link}")
                      page = await fetch_page(session, link)
                      if page:
                          results.append(page)
                  return results

          def make_pdf(pages):
              pdf = FPDF()
              pdf.set_auto_page_break(auto=True, margin=15)
              pdf.set_font("Helvetica", size=12)
              for title, text in pages:
                  pdf.add_page()
                  pdf.set_font("Helvetica", "B", 16)
                  pdf.multi_cell(0, 10, title)
                  pdf.ln(5)
                  pdf.set_font("Helvetica", size=12)
                  pdf.multi_cell(0, 8, text)
              pdf.output("NextJS_Latest_Docs.pdf")
              print("âœ… PDF created successfully.")

          async def main():
              docs = await scrape_docs()
              make_pdf(docs)

          asyncio.run(main())
          EOF

      - name: ğŸ’¾ Commit & Push PDF
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          mv NextJS_Latest_Docs.pdf nextjs_docs_latest.pdf
          git add nextjs_docs_latest.pdf
          git commit -m "ğŸ§­ Update Next.js Docs PDF (auto-generated)"
          git push

      - name: ğŸ“¤ Upload as artifact
        uses: actions/upload-artifact@v4
        with:
          name: nextjs-docs-latest
          path: nextjs_docs_latest.pdf
