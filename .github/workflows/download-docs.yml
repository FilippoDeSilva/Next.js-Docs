name: Next.js Docs PDF

# Triggers: manual and scheduled
on:
  workflow_dispatch:   # Manual trigger
  schedule:            # Automatic trigger
    - cron: '0 0 * * *'  # Every day at midnight UTC

jobs:
  build-docs:
    runs-on: ubuntu-latest

    steps:
      # 1Ô∏è‚É£ Checkout the repository
      - name: Checkout repository
        uses: actions/checkout@v3

      # 2Ô∏è‚É£ Set up Python 3.12
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      # 3Ô∏è‚É£ Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 weasyprint tqdm

      # 4Ô∏è‚É£ Generate Next.js Docs PDF
      - name: Generate PDF
        run: |
          mkdir -p docs_html output

          python - <<'PYTHON_CODE'
import os, requests, re
from bs4 import BeautifulSoup
from weasyprint import HTML, CSS
from pathlib import Path

BASE_URL = "https://nextjs.org/docs"
OUT_DIR = Path("docs_html")
OUT_DIR.mkdir(exist_ok=True)
OUTPUT_PDF = Path("output/Nextjs_Docs_Dark.pdf")

visited = set()
queue = [BASE_URL]
html_files = []

while queue:
    url = queue.pop(0)
    if url in visited:
        continue
    try:
        r = requests.get(url, timeout=20)
        r.raise_for_status()
        html = r.text
        visited.add(url)

        soup = BeautifulSoup(html, "html.parser")

        # Dark theme CSS
        dark_css = """
        html, body { background: #0d1117 !important; color: #c9d1d9 !important; }
        h1,h2,h3,h4,h5,h6 { color: #58a6ff !important; }
        a { color: #58a6ff !important; }
        code, pre { background: #161b22 !important; color: #f0f6fc !important; }
        table, th, td { border: 1px solid #444 !important; }
        """
        style_tag = soup.new_tag("style")
        style_tag.string = dark_css
        if soup.head:
            soup.head.append(style_tag)
        else:
            soup.insert(0, style_tag)

        filename = OUT_DIR / (re.sub(r"[^a-zA-Z0-9]", "_", url.split("/")[-1] or "index") + ".html")
        filename.write_text(str(soup), encoding="utf-8")
        html_files.append(filename)

        for a in soup.find_all("a", href=True):
            href = a["href"]
            if href.startswith("/docs"):
                full_url = "https://nextjs.org" + href
                if full_url not in visited:
                    queue.append(full_url)

        print(f"‚úÖ Downloaded: {url}")
    except Exception as e:
        print(f"‚ùå Failed: {url} ‚Üí {e}")

print(f"Total pages downloaded: {len(html_files)}")

all_html_content = ""
for f in sorted(html_files):
    all_html_content += f.read_text(encoding="utf-8") + "<p style='page-break-after: always;'></p>"

HTML(string=all_html_content).write_pdf(OUTPUT_PDF, stylesheets=[CSS(string="body { font-family: system-ui; }")])
print(f"üìÑ PDF generated: {OUTPUT_PDF}")
PYTHON_CODE 